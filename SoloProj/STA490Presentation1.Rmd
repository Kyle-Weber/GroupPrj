---
title: '<font size = 7 color = "blue">Analyzation of Credit Approval rates using logistic regression.
</font>'
subtitle: '<img src="img/WCU.png" width=100 height=100><img src="img/WCU.png" width=90 height=100> <img src="img/WCU.png" width=90 height=100>'
author: '<font size = 5 color = "blue"> Kyle Weber </font>'
institute: '<font size = 6 color = "blue">West Chester University of Pennsylvania</font><br> '
date: ' <font color = "blue" size =4> Prepared for<br> </font> <br> <font color = "gold" size = 6> STA490: Statistics Capstone </font> <br> <br> <font color = "blue" size = 3> Slides available at: https://github.com/Kyle-Weber/STA490 </font>'
output:
  xaringan::moon_reader:
    css: xaringan-themer01.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
if (!require("knitr")) {
   install.packages("knitr")
   library(knitr)
}
if (!require("pander")) {
   install.packages("pander")
   library(pander)
}
if (!require("plotly")) {
   install.packages("plotly")
   library(plotly)
}
if (!require("ggplot2")) {
   install.packages("ggplot2")
   library(ggplot2)
}
knitr::opts_chunk$set(
                  fig.width=3, 
                  fig.height=3, 
                  fig.retina=12,
                  out.width = "100%",
                  cache = FALSE,
                  echo = TRUE,
                  message = FALSE, 
                  warning = FALSE,
                  hiline = TRUE
                  )
```


```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
  style_duo_accent(primary_color = "#1F4257",
          secondary_color = "#380F2A",
          # fonts
          header_font_google = google_font("Martel"),
          text_font_google = google_font("Lato"),
          code_font_google = google_font("Fira Mono"))
```


```{r, echo=FALSE}
library(mlbench)
Credit.0 <- read.csv("https://raw.githubusercontent.com/Kyle-Weber/STA321/main/www/clean_dataset.csv", header = TRUE)
Credit = Credit.0
```

```{r, echo=FALSE}
library(psych)
num.var <- c("Age", "YearsEmployed", "Income", "Debt")

num.dat <- Credit[, num.var]

pairs.panels(num.dat, 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
)

```

```{r, echo=FALSE}
par(mfrow=c(1,2))
hist(Credit$Debt, xlab="Debt", main = "")
hist(Credit$Income, xlab = "Income", main = "")
hist(Credit$YearsEmployed, xlab = "Worked", main = "")
hist(Credit$Age, xlab = "Age", main = "")

```

```{r, echo=FALSE}
# Specify the breaks for each variable
age.breaks <- c(0, 17.0, 21.0, 26.0, 35.0, 50.0, 100)
income.breaks <- c(-1, 0.0, 5.0, 10.0, 300.0, 5000, Inf)
debt.breaks <- c(-1, 0.0, 0.6, 1.2, 5.0, 10.0, 40, Inf)
years.breaks <- c(-1, 0.0, 1.0, 3.0, 5.0, 10.0, 50, Inf)

# Use cut() function to create new columns with group labels
Credit$grp.Age <- cut(Credit$Age, breaks = age.breaks, labels = c("0-17", "17-21", "21-26", "26-35", "35-50", "50-100"))
Credit$grp.Income <- cut(Credit$Income, breaks = income.breaks, labels = c("0", "0.1-5", "5-10", "10-300", "300-5000", "5000+"))
Credit$grp.Debt <- cut(Credit$Debt, breaks = debt.breaks, labels = c("0", "0.1-0.6", "0.61-1.2", "1.21-5.0", "5.1-10.0", "10.1-40", "40+"))
Credit$grp.YearsEmployed <- cut(Credit$YearsEmployed, breaks = years.breaks, labels = c("0", "0.1-1.0", "3.0-5.0", "5.0-10.0", "10.1-50.0", "50+", ""))

```







---
# Table of Contents

1. Data Set Summary 
<br>
<br>
2. Research Question 
<br>
<br>
3. Exploratory Analysis 
<br>
<br>
4-6. Logistic Regression Models 
<br>
<br>
7. Model Comparison 
<br>
<br>
8. Odds Ratio Analysis 
<br>
<br>
9. Conclusion 


---
# Research Question

- Can a multiple logistic regression model predict credit card approval based on applicantâ€™s demographic and financial information?


---
# Exploratory Analysis

- Pairwise Scatter Plots for Numerical Variables
<br>
    - Seems to be issues regrading skewness and grouping


```{r, echo=FALSE}
library(psych)
num.var <- c("Age", "YearsEmployed", "Income", "Debt")

num.dat <- Credit[, num.var]

pairs.panels(num.dat, 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
)

```

- grouping the histograms will help to fix this problem


---
# Logistic Regression Models

- Full Model
<br>
<br>
- Helps to find variables that are not statistically significant
```{r, echo=FALSE}
full.model = glm(Approved ~grp.Debt+ grp.Age + grp.Income + Gender + BankCustomer + Ethnicity + grp.YearsEmployed + PriorDefault + Employed + CreditScore + DriversLicense,
          family = binomial(link = "logit"),  #  logit(p) = log(p/(1-p))!
          data = Credit)  
kable(summary(full.model)$coef, 
      caption="Summary of inferential statistics of the full model")
```




---
# Logistic Regression Models
- Reduced Model
<br>
<br>
- non-significant variables taken out manually
```{r, echo=FALSE}
reduced.model = glm(Approved ~ grp.Income + grp.Debt + CreditScore + Employed + BankCustomer, 
          family = binomial(link = "logit"),  # logit(p) = log(p/(1-p))!
          data = Credit) 
kable(summary(reduced.model)$coef, 
      caption="Summary of inferential statistics of the reduced model")
```




---
# Logistic Regression Models
- Final Model
<br>
<br>
- automatic variable selection
<br>
<br>
- most relevant variables kept in
```{r, echo=FALSE}
## automatic variable selection
library(MASS)
final.model.forward = stepAIC(reduced.model, 
                      scope = list(lower=formula(reduced.model),upper=formula(full.model)),
                      direction = "forward",   # forward selection
                      trace = 0   # do not show the details
                      )
kable(summary(final.model.forward)$coef, 
      caption="Summary of inferential statistics of the final model")
```









---
# Goodness-of-fit Model Comparison
- Comparison of three logistic regression models. 
<br>
<br>
- final model has a slightly higher Deviance and lower AIC
```{r, echo=FALSE}
## Other global goodness-of-fit
global.measure=function(s.logit){
dev.resid = s.logit$deviance
dev.0.resid = s.logit$null.deviance
aic = s.logit$aic
goodness = cbind(Deviance.residual =dev.resid, Null.Deviance.Residual = dev.0.resid,
      AIC = aic)
goodness
}
goodness=rbind(full.model = global.measure(full.model),
      reduced.model=global.measure(reduced.model),
      final.model=global.measure(final.model.forward))
row.names(goodness) = c("full.model", "reduced.model", "final.model")
kable(goodness, caption ="Comparison of global goodness-of-fit statistics")
```




---
# Odds Ratio  analysis
- performed for a more practical interpretation
<br>
- Income group "0.1-5" has odds ratio 0.1388257, indicating about 86% lower approval odds than the baseline
<br>
- Similar patterns observed for other variables
<br>
- Priordefault is the most influential variable
```{r, echo=FALSE}
# Odds ratio
model.coef.stats = summary(final.model.forward)$coef
odds.ratio = exp(coef(final.model.forward))
out.stats = cbind(model.coef.stats, odds.ratio = odds.ratio)                 
kable(out.stats,caption = "Summary Stats with Odds Ratios")
```





---
#   Conclusion

- Multiple logistic regression serves as a powerful tool for extracting insights from intricate datasets.

- Offers a deeper understanding of the dynamics influencing credit card approval decisions.

- Revealed crucial information about the relationship between credit card approval and predictor variables.

---






































